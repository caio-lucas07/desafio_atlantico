{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTÃO 3 - CATS-DOGS BINARY CLASSIFICATION \n",
    "### Caio Lucas Mesquita de Moraes\n",
    "\n",
    "A classificação binária proposta será resolvida usando o algoritmo de CNN (Convolutional Neural Networks). Devido as limitações de hardware do meu laptop (Lenovo i3, 4gb RAM), usei a VM do _Google Colab_ para compilar o código. Lá podemos usar GPUs de forma gratuita, desde que o uso seja feito com bom senso.\n",
    "\n",
    "O dataset original utilizado pode ser obtido no link **www.kaggle.com/c/dogs-vs-cats/data** (dataset de uma competição). As imagens do dataset são JPEGs coloridos de resolução média.  Para fins de maior velocidade na compilação do código, apenas um subconjunto do dataset foi utilizado. O dataset original possui 25000 imagens de gatos e cachorros (12500 de cada classe), mas usaremos apenas 2000 imagens (2000 de cada classe para treino +  1000 para validation). Cada divisão tem o mesmo número de amostras de cada classe. Por ser um dataset \"balanceado\", a acurácia será uma boa medida de sucesso da classificação.\n",
    "\n",
    "O subconjunto das imagens também foi obtido por meio da internet e o download pode ser feito por meio do link **https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPROCESSING DATA\n",
    "\n",
    "Antes de alimentarmos a rede convolucional, os dados precisam ser formatados de forma apropriada em tensores (multi-arrays). Isso consiste em decodificar as imagens em JPEG para grids de pixels do padrão RGB, convertê-los em tensores de ponto flutuante e re-escalar os valores dos pixels (0-255) para o intervalo [0, 1], devido as redes neurais tratarem melhor dados de entrada com valores pequenos.\n",
    "\n",
    "Outro pré-processamento se dá através do que é chamado _Data Augmentation_. Esse processo é usado para fazer com que o modelo convolucional possa ser exposto a mais aspectos variados do dataset, realizando modificações angulares, _flips_ horizontais e verticais, entre outras transformações. O que resulta disso é que o modelo se \"encaixa\" ( _fit_ ) melhor nos dados de treino e generaliza melhor para novos dados ainda não vistos pela rede, evitando o que é chamado de _overfitting_ , que é quando o modelo é complexo demais, tem alta variância, e acaba sendo impreciso com dados não-vistos.     \n",
    "\n",
    "Para tanto, podemos usar a Keras, que possui um módulo com ferramentas para o pré-processamento de imagens localizado em _keras.preprocessing.image_. com a classe _ImageDataGenerator_ que vai tornar as imagens em _batches_ de tensores pré-processados.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenção do dataset filtrado e definição dos diretórios\n",
    "\n",
    "Com a célula abaixo faz-se o 'mount' do Google Drive, do qual você pode usar a pasta que contém o dataset (pasta chamada \"cats_dogs_dataset\", já dividida em train, validation e test). Na célula seguinte a esta, organizamos os diretórios de treino e validação. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive, files\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "base_dir = '/content/drive/My Drive/cats_dogs_dataset/'  \n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'teste/test_folder')\n",
    "\n",
    "\n",
    "# Diretório com gatos para etapa de treino\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "\n",
    "# Diretório com cachorros para etapa de treino\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "# Diretório com gatos para etapa de validação\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "\n",
    "# Diretório com cachorros para etapa de validação\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "train_cat_fnames = os.listdir(train_cats_dir)\n",
    "train_dog_fnames = os.listdir(train_dogs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA AUGMENTATION PARA CONFIGURAÇÃO DOS DADOS PRÉ-PROCESSADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-escala, rotaciona, translaciona, transformação 'shear'\n",
    "# zoom e 'flip' horizontal \n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Imagens de treino em 32 batches de 20 samples cada, usando o gerador train_datagen\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  # Fonte do diretório para training examples\n",
    "        target_size=(150, 150),  # Imagens formatadas para 150x150\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "# Imagens de validação em 32 batches de 20 samples cada, usando o gerador val_datagen\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPLEMENTAÇÃO DO MODELO\n",
    "\n",
    "O modelo utilizado possui 3 _conv layers_ , 3 _max pooling_ layers, uma camada _fully connected_ com ativação por ReLU e a última camada de resultado softmax, que gera as probabilidades estimadas de classe.\n",
    "Foi adicionado um _dropout_ também no modelo com o objetivo de evitar _overfitting_ ( _dropout_ se compara com a regularização L2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Feature map de entrada com dimensões 150x150x3: 150x150 para pixels das imagens, e 3 para os 3 canais de cor: R, G e B\n",
    "img_input = layers.Input(shape=(150, 150, 3))\n",
    "\n",
    "# Primeira convolução extrai 16 filtros que são 3x3\n",
    "# Convolução é seguida por camada max-pooling com uma janela 2x2 \n",
    "x = layers.Conv2D(16, 3, activation='relu')(img_input)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "# Segunda convolução extrai 32 filtros que são 3x3\n",
    "# Convolução é seguida por camada max-pooling com uma janela 2x2 \n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "# Terceira convolução extrai 64 filtros que são 3x3\n",
    "# Convolução é seguida por camada max-pooling com uma janela 2x2 \n",
    "x = layers.Convolution2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "# Nivela o feature map em tensor unidimensional \n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# Cria camada fully connected com ativação ReLU e 512 hidden units\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Adiciona o dropout\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Cria camada de saída com 1 nó apenas e ativação com função sigmoid\n",
    "# Usa-se a sigmoid devido o problema ser binário \n",
    "output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Configura e compila o modelo\n",
    "model = Model(img_input, output)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),       # Usa o método de otimização RMSprop com learning rate de 0.001  \n",
    "              metrics=['acc'])   # métrica: acurácia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIT DO MODELO NOS DADOS\n",
    "\n",
    "Para treinar o modelo convolucional, usamos o método _fit_generator_. Nele configuramos a quantidade de _epochs_ (número de iterações pelo dataset inteiro) e a quantidade de _batches_ (conjuntos de samples a partir da divisão do dataset, uma vez que não se costuma passar todo o dataset de uma vez para a rede). \n",
    "\n",
    "Nota: o número de epochs (valor atual = 30) pode ser aumentado ou diminuído para um melhor ou menor desempenho do modelo, respectivamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,   # batches\n",
    "      epochs=60,\n",
    "      validation_data=validation_generator,   # dados de validação\n",
    "      validation_steps=50,    # batches dos dados de validação\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cats_dogs_model.h5')  # salva o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AVALIAÇÃO DOS RESULTADOS\n",
    "\n",
    "Como já foi dito, para o problema proposto a acurácia é uma boa medida de sucesso do modelo. A função de perda (loss function) também é usada como parâmetro de sucesso para os modelos. Neste caso, ela precisa ser minimizada. Na célula abaixo está o código que plota as medidas de treino para o modelo. \n",
    "\n",
    "O modelo implementado não obteve uma grande precisão (~ 75%) devido a pouca quantidade de dados e também porque não foram usadas as outras técnicas que podem melhorar o desempenho da rede. Na técninca e.g. de _feature extraction_ se usa redes que já foram treinadas em outros datasets bem maiores e que foram aplicadas em problemas correlacionados com o problema que você está tentando solucionar; por sua vez, é executada adicionando uma rede customizada na rede já treinada, depois \"congelando\" a rede-base (não atualizando os pesos) e treinando a parte que foi adicionada. A técnica complementar a _feature extraction_ é a de _fine tuning_ que consiste em \"descongelar\" as camadas na rede-base e treinar as duas redes: rede-base e rede customizada que foi adicionada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de resultados sobre dados de treinamento e validação\n",
    "# para cada 'epoch' de treino\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Número de epochs\n",
    "epochs = range(len(acc))\n",
    "\n",
    "# Plota precisão de treino e validação por epoch\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Plota 'loss' de treino e validação por epoch\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTE COM DADOS NOVOS \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array, array_to_img\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "test_images_fnames = os.listdir(test_dir)    # nome dos diretórios das imagens usadas no teste \n",
    "img_path = [] \n",
    "\n",
    "for i in range(len(test_images_fnames)):\n",
    "    \n",
    "    img_path = os.path.join(test_dir, test_images_fnames[i])\n",
    "    img = load_img(img_path, target_size=(150, 150))  # imagem PIL \n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.tick_params(top=False, bottom=False, left=False, right=False, labelleft=False, labelbottom=False)\n",
    "\n",
    "    x = img_to_array(img)  # Numpy array com formato (150, 150, 3)\n",
    "    x = x.reshape((1,) + x.shape)  # Numpy array com formato (1, 150, 150, 3)\n",
    "    p = model.predict(x)\n",
    "    p = np.array(p)\n",
    "    \n",
    "    if p < 1:\n",
    "        plt.title('cat')\n",
    "    else:\n",
    "        plt.title('dog')\n",
    "        \n",
    "        \n",
    "                                                                                                                        #SDG"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
